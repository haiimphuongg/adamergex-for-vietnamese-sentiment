nohup: ignoring input
I am here to train LoRA adapters for Llama 3 models.

--- Starting LoRA Adapter Training for: en_clm_adapter ---
Task type: clm
Using base model: meta-llama/Llama-3.2-3B-Instruct
Processed dataset path: ./processed_data/english_clm_corpus_truncated.json
Adapter will be saved to: ./trained_adapters/en_clm_adapter
Trainer checkpoints: ./trained_adapters/en_clm_adapter/trainer_checkpoints
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 20000 examples [00:00, 35278.71 examples/s]Generating train split: 20000 examples [00:00, 35109.84 examples/s]
Loaded dataset with 20000 samples for en_clm_adapter.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.69s/it]
trainable params: 12156928 || all params: 1815620608 || trainable%: 0.67
Applying formatting function to train dataset:   0%|          | 0/20000 [00:00<?, ? examples/s]Applying formatting function to train dataset:  11%|█         | 2200/20000 [00:00<00:00, 21866.66 examples/s]Applying formatting function to train dataset:  23%|██▎       | 4608/20000 [00:00<00:00, 23160.13 examples/s]Applying formatting function to train dataset:  35%|███▌      | 7000/20000 [00:00<00:00, 23077.84 examples/s]Applying formatting function to train dataset:  47%|████▋     | 9453/20000 [00:00<00:00, 23639.35 examples/s]Applying formatting function to train dataset:  65%|██████▍   | 12955/20000 [00:00<00:00, 23502.48 examples/s]Applying formatting function to train dataset:  82%|████████▏ | 16437/20000 [00:00<00:00, 23386.39 examples/s]Applying formatting function to train dataset:  99%|█████████▉| 19870/20000 [00:00<00:00, 23202.01 examples/s]Applying formatting function to train dataset: 100%|██████████| 20000/20000 [00:00<00:00, 23082.57 examples/s]
Converting train dataset to ChatML:   0%|          | 0/20000 [00:00<?, ? examples/s]Converting train dataset to ChatML:  10%|█         | 2000/20000 [00:00<00:00, 19300.22 examples/s]Converting train dataset to ChatML:  23%|██▎       | 4638/20000 [00:00<00:01, 11810.64 examples/s]Converting train dataset to ChatML:  33%|███▎      | 6634/20000 [00:00<00:00, 14211.67 examples/s]Converting train dataset to ChatML:  43%|████▎     | 8635/20000 [00:00<00:00, 15927.66 examples/s]Converting train dataset to ChatML:  53%|█████▎    | 10653/20000 [00:00<00:00, 17189.36 examples/s]Converting train dataset to ChatML:  63%|██████▎   | 12602/20000 [00:00<00:00, 17872.41 examples/s]Converting train dataset to ChatML:  73%|███████▎  | 14602/20000 [00:00<00:00, 18506.24 examples/s]Converting train dataset to ChatML:  83%|████████▎ | 16535/20000 [00:00<00:00, 18749.90 examples/s]Converting train dataset to ChatML:  92%|█████████▏| 18480/20000 [00:01<00:00, 18956.98 examples/s]Converting train dataset to ChatML: 100%|██████████| 20000/20000 [00:01<00:00, 17293.84 examples/s]
Adding EOS to train dataset:   0%|          | 0/20000 [00:00<?, ? examples/s]Adding EOS to train dataset:  11%|█         | 2208/20000 [00:00<00:00, 21982.49 examples/s]Adding EOS to train dataset:  22%|██▏       | 4467/20000 [00:00<00:00, 22336.49 examples/s]Adding EOS to train dataset:  34%|███▎      | 6724/20000 [00:00<00:00, 22439.13 examples/s]Adding EOS to train dataset:  45%|████▍     | 8988/20000 [00:00<00:00, 22515.50 examples/s]Adding EOS to train dataset:  62%|██████▏   | 12325/20000 [00:00<00:00, 22276.73 examples/s]Adding EOS to train dataset:  73%|███████▎  | 14664/20000 [00:00<00:00, 22611.02 examples/s]Adding EOS to train dataset:  85%|████████▍ | 16967/20000 [00:00<00:00, 22735.88 examples/s]Adding EOS to train dataset: 100%|██████████| 20000/20000 [00:00<00:00, 22146.08 examples/s]Adding EOS to train dataset: 100%|██████████| 20000/20000 [00:00<00:00, 22284.33 examples/s]
Tokenizing train dataset:   0%|          | 0/20000 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 87/20000 [00:00<00:23, 856.16 examples/s]Tokenizing train dataset:   1%|          | 178/20000 [00:00<00:22, 879.99 examples/s]Tokenizing train dataset:   1%|▏         | 269/20000 [00:00<00:22, 887.77 examples/s]Tokenizing train dataset:   2%|▏         | 360/20000 [00:00<00:22, 891.67 examples/s]Tokenizing train dataset:   2%|▏         | 451/20000 [00:00<00:21, 895.40 examples/s]Tokenizing train dataset:   3%|▎         | 584/20000 [00:00<00:21, 888.68 examples/s]Tokenizing train dataset:   3%|▎         | 674/20000 [00:00<00:21, 886.91 examples/s]Tokenizing train dataset:   4%|▍         | 764/20000 [00:00<00:21, 887.47 examples/s]Tokenizing train dataset:   4%|▍         | 853/20000 [00:00<00:21, 884.06 examples/s]Tokenizing train dataset:   5%|▍         | 942/20000 [00:01<00:21, 882.82 examples/s]Tokenizing train dataset:   5%|▌         | 1041/20000 [00:01<00:28, 676.69 examples/s]Tokenizing train dataset:   6%|▌         | 1126/20000 [00:01<00:26, 717.15 examples/s]Tokenizing train dataset:   6%|▌         | 1212/20000 [00:01<00:25, 751.44 examples/s]Tokenizing train dataset:   6%|▋         | 1298/20000 [00:01<00:24, 776.87 examples/s]Tokenizing train dataset:   7%|▋         | 1385/20000 [00:01<00:23, 798.95 examples/s]Tokenizing train dataset:   7%|▋         | 1472/20000 [00:01<00:22, 817.21 examples/s]Tokenizing train dataset:   8%|▊         | 1557/20000 [00:01<00:22, 823.03 examples/s]Tokenizing train dataset:   8%|▊         | 1645/20000 [00:01<00:21, 835.67 examples/s]Tokenizing train dataset:   9%|▊         | 1733/20000 [00:02<00:21, 845.27 examples/s]Tokenizing train dataset:   9%|▉         | 1821/20000 [00:02<00:21, 851.45 examples/s]Tokenizing train dataset:  10%|▉         | 1909/20000 [00:02<00:21, 857.02 examples/s]Tokenizing train dataset:  10%|▉         | 1997/20000 [00:02<00:20, 858.84 examples/s]Tokenizing train dataset:  10%|█         | 2086/20000 [00:02<00:26, 663.81 examples/s]Tokenizing train dataset:  11%|█         | 2175/20000 [00:02<00:24, 715.17 examples/s]Tokenizing train dataset:  11%|█▏        | 2263/20000 [00:02<00:23, 756.85 examples/s]Tokenizing train dataset:  12%|█▏        | 2351/20000 [00:02<00:22, 788.10 examples/s]Tokenizing train dataset:  12%|█▏        | 2439/20000 [00:03<00:21, 811.68 examples/s]Tokenizing train dataset:  13%|█▎        | 2527/20000 [00:03<00:21, 828.39 examples/s]Tokenizing train dataset:  13%|█▎        | 2616/20000 [00:03<00:20, 842.47 examples/s]Tokenizing train dataset:  14%|█▎        | 2744/20000 [00:03<00:20, 844.39 examples/s]Tokenizing train dataset:  14%|█▍        | 2831/20000 [00:03<00:20, 847.74 examples/s]Tokenizing train dataset:  15%|█▍        | 2919/20000 [00:03<00:19, 854.90 examples/s]Tokenizing train dataset:  15%|█▌        | 3042/20000 [00:03<00:25, 674.83 examples/s]Tokenizing train dataset:  16%|█▌        | 3130/20000 [00:03<00:23, 717.43 examples/s]Tokenizing train dataset:  16%|█▌        | 3218/20000 [00:04<00:22, 753.81 examples/s]Tokenizing train dataset:  17%|█▋        | 3306/20000 [00:04<00:21, 783.48 examples/s]Tokenizing train dataset:  17%|█▋        | 3395/20000 [00:04<00:20, 808.71 examples/s]Tokenizing train dataset:  17%|█▋        | 3483/20000 [00:04<00:19, 826.20 examples/s]Tokenizing train dataset:  18%|█▊        | 3569/20000 [00:04<00:19, 833.61 examples/s]Tokenizing train dataset:  18%|█▊        | 3657/20000 [00:04<00:19, 844.28 examples/s]Tokenizing train dataset:  19%|█▊        | 3744/20000 [00:04<00:19, 848.55 examples/s]Tokenizing train dataset:  19%|█▉        | 3831/20000 [00:04<00:18, 852.72 examples/s]Tokenizing train dataset:  20%|█▉        | 3919/20000 [00:04<00:18, 858.96 examples/s]Tokenizing train dataset:  20%|██        | 4042/20000 [00:05<00:23, 678.82 examples/s]Tokenizing train dataset:  21%|██        | 4129/20000 [00:05<00:21, 721.71 examples/s]Tokenizing train dataset:  21%|██        | 4216/20000 [00:05<00:20, 757.13 examples/s]Tokenizing train dataset:  22%|██▏       | 4303/20000 [00:05<00:20, 784.16 examples/s]Tokenizing train dataset:  22%|██▏       | 4391/20000 [00:05<00:19, 806.50 examples/s]Tokenizing train dataset:  22%|██▏       | 4480/20000 [00:05<00:18, 824.94 examples/s]Tokenizing train dataset:  23%|██▎       | 4565/20000 [00:05<00:18, 828.24 examples/s]Tokenizing train dataset:  23%|██▎       | 4654/20000 [00:05<00:18, 842.56 examples/s]Tokenizing train dataset:  24%|██▎       | 4742/20000 [00:05<00:17, 849.72 examples/s]Tokenizing train dataset:  24%|██▍       | 4830/20000 [00:05<00:17, 855.03 examples/s]Tokenizing train dataset:  25%|██▍       | 4918/20000 [00:06<00:17, 859.70 examples/s]Tokenizing train dataset:  25%|██▌       | 5042/20000 [00:06<00:21, 680.19 examples/s]Tokenizing train dataset:  26%|██▌       | 5125/20000 [00:06<00:20, 711.89 examples/s]Tokenizing train dataset:  26%|██▌       | 5210/20000 [00:06<00:19, 743.65 examples/s]Tokenizing train dataset:  26%|██▋       | 5295/20000 [00:06<00:19, 769.79 examples/s]Tokenizing train dataset:  27%|██▋       | 5381/20000 [00:06<00:18, 792.83 examples/s]Tokenizing train dataset:  27%|██▋       | 5468/20000 [00:06<00:17, 810.25 examples/s]Tokenizing train dataset:  28%|██▊       | 5554/20000 [00:06<00:17, 822.53 examples/s]Tokenizing train dataset:  28%|██▊       | 5642/20000 [00:07<00:17, 838.15 examples/s]Tokenizing train dataset:  29%|██▊       | 5730/20000 [00:07<00:16, 845.02 examples/s]Tokenizing train dataset:  29%|██▉       | 5818/20000 [00:07<00:16, 851.40 examples/s]Tokenizing train dataset:  30%|██▉       | 5907/20000 [00:07<00:16, 859.39 examples/s]Tokenizing train dataset:  30%|███       | 6000/20000 [00:07<00:21, 652.79 examples/s]Tokenizing train dataset:  30%|███       | 6084/20000 [00:07<00:19, 696.16 examples/s]Tokenizing train dataset:  31%|███       | 6170/20000 [00:07<00:18, 736.83 examples/s]Tokenizing train dataset:  31%|███▏      | 6256/20000 [00:07<00:17, 769.11 examples/s]Tokenizing train dataset:  32%|███▏      | 6343/20000 [00:07<00:17, 793.50 examples/s]Tokenizing train dataset:  32%|███▏      | 6429/20000 [00:08<00:16, 811.66 examples/s]Tokenizing train dataset:  33%|███▎      | 6517/20000 [00:08<00:16, 829.48 examples/s]Tokenizing train dataset:  33%|███▎      | 6605/20000 [00:08<00:15, 842.21 examples/s]Tokenizing train dataset:  33%|███▎      | 6693/20000 [00:08<00:15, 851.94 examples/s]Tokenizing train dataset:  34%|███▍      | 6782/20000 [00:08<00:15, 859.92 examples/s]Tokenizing train dataset:  34%|███▍      | 6870/20000 [00:08<00:15, 862.43 examples/s]Tokenizing train dataset:  35%|███▍      | 6958/20000 [00:08<00:15, 866.54 examples/s]Tokenizing train dataset:  35%|███▌      | 7085/20000 [00:08<00:19, 679.15 examples/s]Tokenizing train dataset:  36%|███▌      | 7169/20000 [00:09<00:17, 713.69 examples/s]Tokenizing train dataset:  36%|███▋      | 7256/20000 [00:09<00:17, 748.55 examples/s]Tokenizing train dataset:  37%|███▋      | 7343/20000 [00:09<00:16, 776.14 examples/s]Tokenizing train dataset:  37%|███▋      | 7429/20000 [00:09<00:15, 797.38 examples/s]Tokenizing train dataset:  38%|███▊      | 7516/20000 [00:09<00:15, 815.27 examples/s]Tokenizing train dataset:  38%|███▊      | 7643/20000 [00:09<00:15, 822.32 examples/s]Tokenizing train dataset:  39%|███▊      | 7730/20000 [00:09<00:14, 830.14 examples/s]Tokenizing train dataset:  39%|███▉      | 7818/20000 [00:09<00:14, 840.57 examples/s]Tokenizing train dataset:  40%|███▉      | 7903/20000 [00:09<00:14, 841.19 examples/s]Tokenizing train dataset:  40%|███▉      | 7992/20000 [00:09<00:14, 852.71 examples/s]Tokenizing train dataset:  40%|████      | 8084/20000 [00:10<00:18, 655.14 examples/s]Tokenizing train dataset:  41%|████      | 8167/20000 [00:10<00:17, 694.69 examples/s]Tokenizing train dataset:  41%|████▏     | 8253/20000 [00:10<00:15, 734.89 examples/s]Tokenizing train dataset:  42%|████▏     | 8339/20000 [00:10<00:15, 765.60 examples/s]Tokenizing train dataset:  42%|████▏     | 8425/20000 [00:10<00:14, 790.17 examples/s]Tokenizing train dataset:  43%|████▎     | 8513/20000 [00:10<00:14, 812.59 examples/s]Tokenizing train dataset:  43%|████▎     | 8600/20000 [00:10<00:13, 826.76 examples/s]Tokenizing train dataset:  43%|████▎     | 8688/20000 [00:10<00:13, 840.83 examples/s]Tokenizing train dataset:  44%|████▍     | 8776/20000 [00:11<00:13, 849.13 examples/s]Tokenizing train dataset:  44%|████▍     | 8864/20000 [00:11<00:13, 854.51 examples/s]Tokenizing train dataset:  45%|████▍     | 8952/20000 [00:11<00:12, 859.91 examples/s]Tokenizing train dataset:  45%|████▌     | 9041/20000 [00:11<00:16, 651.24 examples/s]Tokenizing train dataset:  46%|████▌     | 9127/20000 [00:11<00:15, 698.59 examples/s]Tokenizing train dataset:  46%|████▌     | 9213/20000 [00:11<00:14, 737.78 examples/s]Tokenizing train dataset:  46%|████▋     | 9299/20000 [00:11<00:13, 768.62 examples/s]Tokenizing train dataset:  47%|████▋     | 9385/20000 [00:11<00:13, 791.16 examples/s]Tokenizing train dataset:  47%|████▋     | 9470/20000 [00:11<00:13, 805.70 examples/s]Tokenizing train dataset:  48%|████▊     | 9556/20000 [00:12<00:12, 818.27 examples/s]Tokenizing train dataset:  48%|████▊     | 9644/20000 [00:12<00:12, 835.15 examples/s]Tokenizing train dataset:  49%|████▊     | 9731/20000 [00:12<00:12, 844.41 examples/s]Tokenizing train dataset:  49%|████▉     | 9819/20000 [00:12<00:11, 850.61 examples/s]Tokenizing train dataset:  50%|████▉     | 9908/20000 [00:12<00:11, 859.46 examples/s]Tokenizing train dataset:  50%|████▉     | 9998/20000 [00:12<00:11, 864.92 examples/s]Tokenizing train dataset:  50%|█████     | 10085/20000 [00:12<00:15, 659.05 examples/s]Tokenizing train dataset:  51%|█████     | 10171/20000 [00:12<00:13, 705.30 examples/s]Tokenizing train dataset:  51%|█████▏    | 10257/20000 [00:12<00:13, 743.47 examples/s]Tokenizing train dataset:  52%|█████▏    | 10342/20000 [00:13<00:12, 769.52 examples/s]Tokenizing train dataset:  52%|█████▏    | 10428/20000 [00:13<00:12, 792.69 examples/s]Tokenizing train dataset:  53%|█████▎    | 10515/20000 [00:13<00:11, 813.77 examples/s]Tokenizing train dataset:  53%|█████▎    | 10600/20000 [00:13<00:11, 820.58 examples/s]Tokenizing train dataset:  53%|█████▎    | 10688/20000 [00:13<00:11, 835.59 examples/s]Tokenizing train dataset:  54%|█████▍    | 10775/20000 [00:13<00:10, 842.82 examples/s]Tokenizing train dataset:  54%|█████▍    | 10863/20000 [00:13<00:10, 849.93 examples/s]Tokenizing train dataset:  55%|█████▍    | 10950/20000 [00:13<00:10, 853.88 examples/s]Tokenizing train dataset:  55%|█████▌    | 11042/20000 [00:13<00:13, 655.91 examples/s]Tokenizing train dataset:  56%|█████▌    | 11128/20000 [00:14<00:12, 703.28 examples/s]Tokenizing train dataset:  56%|█████▌    | 11214/20000 [00:14<00:11, 741.14 examples/s]Tokenizing train dataset:  56%|█████▋    | 11300/20000 [00:14<00:11, 771.18 examples/s]Tokenizing train dataset:  57%|█████▋    | 11387/20000 [00:14<00:10, 794.72 examples/s]Tokenizing train dataset:  57%|█████▋    | 11474/20000 [00:14<00:10, 811.44 examples/s]Tokenizing train dataset:  58%|█████▊    | 11561/20000 [00:14<00:10, 826.19 examples/s]Tokenizing train dataset:  58%|█████▊    | 11650/20000 [00:14<00:09, 840.75 examples/s]Tokenizing train dataset:  59%|█████▊    | 11737/20000 [00:14<00:09, 847.96 examples/s]/venv/main/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:597: UserWarning: Mismatch between tokenized prompt and the start of tokenized prompt+completion. This may be due to unexpected tokenizer behavior, whitespace issues, or special token handling. Verify that the tokenizer is processing text consistently.
  warnings.warn(
Tokenizing train dataset:  59%|█████▉    | 11825/20000 [00:14<00:09, 853.85 examples/s]Tokenizing train dataset:  60%|█████▉    | 11913/20000 [00:14<00:09, 859.73 examples/s]Tokenizing train dataset:  60%|██████    | 12000/20000 [00:15<00:12, 655.84 examples/s]Tokenizing train dataset:  60%|██████    | 12085/20000 [00:15<00:11, 700.46 examples/s]Tokenizing train dataset:  61%|██████    | 12170/20000 [00:15<00:10, 736.95 examples/s]Tokenizing train dataset:  61%|██████▏   | 12256/20000 [00:15<00:10, 769.28 examples/s]Tokenizing train dataset:  62%|██████▏   | 12342/20000 [00:15<00:09, 792.17 examples/s]Tokenizing train dataset:  62%|██████▏   | 12429/20000 [00:15<00:09, 810.80 examples/s]Tokenizing train dataset:  63%|██████▎   | 12517/20000 [00:15<00:09, 828.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 12605/20000 [00:15<00:08, 841.05 examples/s]Tokenizing train dataset:  63%|██████▎   | 12693/20000 [00:15<00:08, 849.78 examples/s]Tokenizing train dataset:  64%|██████▍   | 12782/20000 [00:16<00:08, 857.68 examples/s]Tokenizing train dataset:  64%|██████▍   | 12870/20000 [00:16<00:08, 860.97 examples/s]Tokenizing train dataset:  65%|██████▍   | 12959/20000 [00:16<00:08, 865.68 examples/s]Tokenizing train dataset:  65%|██████▌   | 13085/20000 [00:16<00:10, 679.81 examples/s]Tokenizing train dataset:  66%|██████▌   | 13171/20000 [00:16<00:09, 717.72 examples/s]Tokenizing train dataset:  66%|██████▋   | 13258/20000 [00:16<00:08, 752.61 examples/s]Tokenizing train dataset:  67%|██████▋   | 13345/20000 [00:16<00:08, 779.93 examples/s]Tokenizing train dataset:  67%|██████▋   | 13431/20000 [00:16<00:08, 800.09 examples/s]Tokenizing train dataset:  68%|██████▊   | 13518/20000 [00:17<00:07, 817.58 examples/s]Tokenizing train dataset:  68%|██████▊   | 13646/20000 [00:17<00:07, 827.37 examples/s]Tokenizing train dataset:  69%|██████▊   | 13733/20000 [00:17<00:07, 836.28 examples/s]Tokenizing train dataset:  69%|██████▉   | 13820/20000 [00:17<00:07, 842.76 examples/s]Tokenizing train dataset:  70%|██████▉   | 13906/20000 [00:17<00:07, 845.11 examples/s]Tokenizing train dataset:  70%|██████▉   | 13993/20000 [00:17<00:07, 848.48 examples/s]Tokenizing train dataset:  70%|███████   | 14086/20000 [00:17<00:09, 652.84 examples/s]Tokenizing train dataset:  71%|███████   | 14172/20000 [00:17<00:08, 699.96 examples/s]Tokenizing train dataset:  71%|███████▏  | 14259/20000 [00:18<00:07, 739.76 examples/s]Tokenizing train dataset:  72%|███████▏  | 14346/20000 [00:18<00:07, 771.88 examples/s]Tokenizing train dataset:  72%|███████▏  | 14433/20000 [00:18<00:06, 796.73 examples/s]Tokenizing train dataset:  73%|███████▎  | 14521/20000 [00:18<00:06, 817.84 examples/s]Tokenizing train dataset:  73%|███████▎  | 14609/20000 [00:18<00:06, 832.52 examples/s]Tokenizing train dataset:  73%|███████▎  | 14698/20000 [00:18<00:06, 845.20 examples/s]Tokenizing train dataset:  74%|███████▍  | 14786/20000 [00:18<00:06, 852.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 14874/20000 [00:18<00:05, 858.42 examples/s]Tokenizing train dataset:  75%|███████▍  | 14962/20000 [00:18<00:05, 863.76 examples/s]Tokenizing train dataset:  75%|███████▌  | 15086/20000 [00:19<00:07, 673.62 examples/s]Tokenizing train dataset:  76%|███████▌  | 15173/20000 [00:19<00:06, 716.72 examples/s]Tokenizing train dataset:  76%|███████▋  | 15261/20000 [00:19<00:06, 754.42 examples/s]Tokenizing train dataset:  77%|███████▋  | 15348/20000 [00:19<00:05, 782.12 examples/s]Tokenizing train dataset:  77%|███████▋  | 15436/20000 [00:19<00:05, 805.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 15524/20000 [00:19<00:05, 823.49 examples/s]Tokenizing train dataset:  78%|███████▊  | 15611/20000 [00:19<00:05, 834.72 examples/s]Tokenizing train dataset:  78%|███████▊  | 15698/20000 [00:19<00:05, 844.04 examples/s]Tokenizing train dataset:  79%|███████▉  | 15787/20000 [00:19<00:04, 853.57 examples/s]Tokenizing train dataset:  79%|███████▉  | 15876/20000 [00:19<00:04, 859.06 examples/s]Tokenizing train dataset:  80%|███████▉  | 15964/20000 [00:20<00:04, 864.74 examples/s]Tokenizing train dataset:  80%|████████  | 16086/20000 [00:20<00:05, 676.94 examples/s]Tokenizing train dataset:  81%|████████  | 16172/20000 [00:20<00:05, 715.57 examples/s]Tokenizing train dataset:  81%|████████▏ | 16257/20000 [00:20<00:05, 748.25 examples/s]Tokenizing train dataset:  82%|████████▏ | 16344/20000 [00:20<00:04, 776.54 examples/s]Tokenizing train dataset:  82%|████████▏ | 16430/20000 [00:20<00:04, 798.79 examples/s]Tokenizing train dataset:  83%|████████▎ | 16518/20000 [00:20<00:04, 818.13 examples/s]Tokenizing train dataset:  83%|████████▎ | 16603/20000 [00:20<00:04, 825.01 examples/s]Tokenizing train dataset:  83%|████████▎ | 16691/20000 [00:21<00:03, 838.56 examples/s]Tokenizing train dataset:  84%|████████▍ | 16779/20000 [00:21<00:03, 847.89 examples/s]Tokenizing train dataset:  84%|████████▍ | 16867/20000 [00:21<00:03, 854.78 examples/s]Tokenizing train dataset:  85%|████████▍ | 16955/20000 [00:21<00:03, 860.52 examples/s]Tokenizing train dataset:  85%|████████▌ | 17043/20000 [00:21<00:04, 664.33 examples/s]Tokenizing train dataset:  86%|████████▌ | 17131/20000 [00:21<00:04, 715.86 examples/s]Tokenizing train dataset:  86%|████████▌ | 17218/20000 [00:21<00:03, 753.99 examples/s]Tokenizing train dataset:  87%|████████▋ | 17306/20000 [00:21<00:03, 785.39 examples/s]Tokenizing train dataset:  87%|████████▋ | 17395/20000 [00:21<00:03, 811.55 examples/s]Tokenizing train dataset:  87%|████████▋ | 17484/20000 [00:22<00:03, 830.00 examples/s]Tokenizing train dataset:  88%|████████▊ | 17572/20000 [00:22<00:02, 841.45 examples/s]Tokenizing train dataset:  88%|████████▊ | 17661/20000 [00:22<00:02, 851.65 examples/s]Tokenizing train dataset:  89%|████████▊ | 17749/20000 [00:22<00:02, 857.81 examples/s]Tokenizing train dataset:  89%|████████▉ | 17837/20000 [00:22<00:02, 862.40 examples/s]Tokenizing train dataset:  90%|████████▉ | 17926/20000 [00:22<00:02, 867.29 examples/s]Tokenizing train dataset:  90%|█████████ | 18042/20000 [00:22<00:02, 672.80 examples/s]Tokenizing train dataset:  91%|█████████ | 18128/20000 [00:22<00:02, 715.03 examples/s]Tokenizing train dataset:  91%|█████████ | 18214/20000 [00:23<00:02, 748.70 examples/s]Tokenizing train dataset:  92%|█████████▏| 18300/20000 [00:23<00:02, 777.57 examples/s]Tokenizing train dataset:  92%|█████████▏| 18388/20000 [00:23<00:02, 801.73 examples/s]Tokenizing train dataset:  92%|█████████▏| 18475/20000 [00:23<00:01, 818.01 examples/s]Tokenizing train dataset:  93%|█████████▎| 18563/20000 [00:23<00:01, 832.77 examples/s]Tokenizing train dataset:  93%|█████████▎| 18652/20000 [00:23<00:01, 846.34 examples/s]Tokenizing train dataset:  94%|█████████▎| 18740/20000 [00:23<00:01, 851.91 examples/s]Tokenizing train dataset:  94%|█████████▍| 18829/20000 [00:23<00:01, 858.87 examples/s]Tokenizing train dataset:  95%|█████████▍| 18917/20000 [00:23<00:01, 862.91 examples/s]Tokenizing train dataset:  95%|█████████▌| 19042/20000 [00:24<00:01, 674.41 examples/s]Tokenizing train dataset:  96%|█████████▌| 19130/20000 [00:24<00:01, 717.95 examples/s]Tokenizing train dataset:  96%|█████████▌| 19218/20000 [00:24<00:01, 754.55 examples/s]Tokenizing train dataset:  97%|█████████▋| 19306/20000 [00:24<00:00, 783.97 examples/s]Tokenizing train dataset:  97%|█████████▋| 19394/20000 [00:24<00:00, 808.84 examples/s]Tokenizing train dataset:  97%|█████████▋| 19483/20000 [00:24<00:00, 828.12 examples/s]Tokenizing train dataset:  98%|█████████▊| 19612/20000 [00:24<00:00, 835.30 examples/s]Tokenizing train dataset:  98%|█████████▊| 19700/20000 [00:24<00:00, 843.11 examples/s]Tokenizing train dataset:  99%|█████████▉| 19788/20000 [00:24<00:00, 849.93 examples/s]Tokenizing train dataset:  99%|█████████▉| 19876/20000 [00:25<00:00, 854.27 examples/s]Tokenizing train dataset: 100%|█████████▉| 19964/20000 [00:25<00:00, 858.35 examples/s]Tokenizing train dataset: 100%|██████████| 20000/20000 [00:25<00:00, 791.11 examples/s]
Truncating train dataset:   0%|          | 0/20000 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 20000/20000 [00:00<00:00, 386087.85 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting SFTTrainer training for en_clm_adapter...
  0%|          | 0/498 [00:00<?, ?it/s]  0%|          | 1/498 [00:17<2:26:56, 17.74s/it]  0%|          | 2/498 [00:34<2:23:23, 17.35s/it]  1%|          | 3/498 [00:51<2:22:28, 17.27s/it]  1%|          | 4/498 [01:09<2:23:38, 17.45s/it]  1%|          | 5/498 [01:26<2:22:49, 17.38s/it]  1%|          | 6/498 [01:44<2:22:42, 17.40s/it]  1%|▏         | 7/498 [02:01<2:21:39, 17.31s/it]  2%|▏         | 8/498 [02:18<2:21:40, 17.35s/it]  2%|▏         | 9/498 [02:36<2:22:01, 17.43s/it]  2%|▏         | 10/498 [02:53<2:21:23, 17.38s/it]                                                  {'loss': 2.6597, 'grad_norm': 1.387182354927063, 'learning_rate': 7.2e-05, 'num_tokens': 308379.0, 'mean_token_accuracy': 0.4470689699053764, 'epoch': 0.06}
  2%|▏         | 10/498 [02:53<2:21:23, 17.38s/it]  2%|▏         | 11/498 [03:11<2:21:13, 17.40s/it]  2%|▏         | 12/498 [03:28<2:21:25, 17.46s/it]  3%|▎         | 13/498 [03:46<2:20:40, 17.40s/it]  3%|▎         | 14/498 [04:03<2:19:40, 17.31s/it]  3%|▎         | 15/498 [04:20<2:19:38, 17.35s/it]  3%|▎         | 16/498 [04:38<2:19:56, 17.42s/it]  3%|▎         | 17/498 [04:55<2:19:15, 17.37s/it]  4%|▎         | 18/498 [05:12<2:19:05, 17.39s/it]  4%|▍         | 19/498 [05:30<2:19:17, 17.45s/it]  4%|▍         | 20/498 [05:47<2:18:32, 17.39s/it]                                                  {'loss': 2.6114, 'grad_norm': 1.7636979818344116, 'learning_rate': 0.000152, 'num_tokens': 616747.0, 'mean_token_accuracy': 0.4591666743159294, 'epoch': 0.12}
  4%|▍         | 20/498 [05:47<2:18:32, 17.39s/it]  4%|▍         | 21/498 [06:05<2:18:42, 17.45s/it]  4%|▍         | 22/498 [06:22<2:18:23, 17.45s/it]  5%|▍         | 23/498 [06:40<2:18:24, 17.48s/it]  5%|▍         | 24/498 [06:57<2:18:20, 17.51s/it]  5%|▌         | 25/498 [07:15<2:17:48, 17.48s/it]  5%|▌         | 26/498 [07:32<2:17:41, 17.50s/it]  5%|▌         | 27/498 [07:50<2:17:06, 17.47s/it]  6%|▌         | 28/498 [08:07<2:16:58, 17.49s/it]  6%|▌         | 29/498 [08:25<2:16:25, 17.45s/it]  6%|▌         | 30/498 [08:42<2:15:57, 17.43s/it]                                                  {'loss': 2.5931, 'grad_norm': 1.6891608238220215, 'learning_rate': 0.00019996471079244477, 'num_tokens': 925104.0, 'mean_token_accuracy': 0.46583334133028986, 'epoch': 0.18}
  6%|▌         | 30/498 [08:42<2:15:57, 17.43s/it]  6%|▌         | 31/498 [08:59<2:15:32, 17.42s/it]  6%|▋         | 32/498 [09:17<2:15:08, 17.40s/it]  7%|▋         | 33/498 [09:34<2:14:02, 17.30s/it]  7%|▋         | 34/498 [09:51<2:14:17, 17.37s/it]  7%|▋         | 35/498 [10:09<2:14:00, 17.37s/it]  7%|▋         | 36/498 [10:26<2:14:06, 17.42s/it]  7%|▋         | 37/498 [10:44<2:13:43, 17.40s/it]  8%|▊         | 38/498 [11:01<2:13:46, 17.45s/it]  8%|▊         | 39/498 [11:19<2:13:42, 17.48s/it]  8%|▊         | 40/498 [11:36<2:13:35, 17.50s/it]                                                  {'loss': 2.4837, 'grad_norm': 2.2268612384796143, 'learning_rate': 0.00019956799318824776, 'num_tokens': 1233467.0, 'mean_token_accuracy': 0.4766666740179062, 'epoch': 0.24}
  8%|▊         | 40/498 [11:36<2:13:35, 17.50s/it]  8%|▊         | 41/498 [11:54<2:13:04, 17.47s/it]  8%|▊         | 42/498 [12:11<2:11:54, 17.36s/it]  9%|▊         | 43/498 [12:28<2:12:07, 17.42s/it]  9%|▉         | 44/498 [12:46<2:11:47, 17.42s/it]  9%|▉         | 45/498 [13:03<2:11:29, 17.42s/it]  9%|▉         | 46/498 [13:21<2:10:49, 17.37s/it]  9%|▉         | 47/498 [13:38<2:10:16, 17.33s/it] 10%|▉         | 48/498 [13:55<2:09:26, 17.26s/it] 10%|▉         | 49/498 [14:12<2:09:07, 17.25s/it] 10%|█         | 50/498 [14:29<2:09:09, 17.30s/it]                                                  {'loss': 2.4896, 'grad_norm': 2.538813829421997, 'learning_rate': 0.00019873220174902858, 'num_tokens': 1541839.0, 'mean_token_accuracy': 0.4641666725277901, 'epoch': 0.3}
 10%|█         | 50/498 [14:29<2:09:09, 17.30s/it] 10%|█         | 51/498 [14:47<2:08:44, 17.28s/it] 10%|█         | 52/498 [15:04<2:07:59, 17.22s/it] 11%|█         | 53/498 [15:21<2:07:44, 17.22s/it] 11%|█         | 54/498 [15:38<2:07:49, 17.27s/it] 11%|█         | 55/498 [15:56<2:07:48, 17.31s/it] 11%|█         | 56/498 [16:13<2:08:05, 17.39s/it] 11%|█▏        | 57/498 [16:31<2:07:50, 17.39s/it] 12%|█▏        | 58/498 [16:48<2:07:56, 17.45s/it] 12%|█▏        | 59/498 [17:06<2:07:35, 17.44s/it] 12%|█▏        | 60/498 [17:23<2:07:36, 17.48s/it]                                                  {'loss': 2.6494, 'grad_norm': 2.4249110221862793, 'learning_rate': 0.00019746102213863114, 'num_tokens': 1850208.0, 'mean_token_accuracy': 0.46416667737066747, 'epoch': 0.36}
 12%|█▏        | 60/498 [17:23<2:07:36, 17.48s/it] 12%|█▏        | 61/498 [17:41<2:07:11, 17.46s/it] 12%|█▏        | 62/498 [17:58<2:06:48, 17.45s/it] 13%|█▎        | 63/498 [18:15<2:06:06, 17.39s/it] 13%|█▎        | 64/498 [18:33<2:05:52, 17.40s/it] 13%|█▎        | 65/498 [18:50<2:05:58, 17.46s/it] 13%|█▎        | 66/498 [19:08<2:05:14, 17.40s/it] 13%|█▎        | 67/498 [19:25<2:04:59, 17.40s/it] 14%|█▎        | 68/498 [19:43<2:05:43, 17.54s/it] 14%|█▍        | 69/498 [20:00<2:04:48, 17.45s/it] 14%|█▍        | 70/498 [20:18<2:04:04, 17.39s/it]                                                  {'loss': 2.5698, 'grad_norm': 1.9582700729370117, 'learning_rate': 0.0001957600599908406, 'num_tokens': 2158576.0, 'mean_token_accuracy': 0.4658333405852318, 'epoch': 0.42}
 14%|█▍        | 70/498 [20:18<2:04:04, 17.39s/it] 14%|█▍        | 71/498 [20:35<2:03:29, 17.35s/it] 14%|█▍        | 72/498 [20:52<2:03:18, 17.37s/it] 15%|█▍        | 73/498 [21:09<2:02:44, 17.33s/it] 15%|█▍        | 74/498 [21:27<2:02:34, 17.35s/it] 15%|█▌        | 75/498 [21:44<2:02:43, 17.41s/it] 15%|█▌        | 76/498 [22:02<2:02:25, 17.41s/it] 15%|█▌        | 77/498 [22:19<2:02:08, 17.41s/it] 16%|█▌        | 78/498 [22:36<2:01:32, 17.36s/it] 16%|█▌        | 79/498 [22:54<2:01:40, 17.42s/it] 16%|█▌        | 80/498 [23:11<2:01:23, 17.42s/it]                                                  {'loss': 2.54, 'grad_norm': 2.4943435192108154, 'learning_rate': 0.00019363681618972164, 'num_tokens': 2466925.0, 'mean_token_accuracy': 0.45833333730697634, 'epoch': 0.48}
 16%|█▌        | 80/498 [23:11<2:01:23, 17.42s/it] 16%|█▋        | 81/498 [23:29<2:00:46, 17.38s/it] 16%|█▋        | 82/498 [23:46<2:00:15, 17.34s/it] 17%|█▋        | 83/498 [24:03<2:00:08, 17.37s/it] 17%|█▋        | 84/498 [24:21<2:00:01, 17.40s/it] 17%|█▋        | 85/498 [24:38<1:59:30, 17.36s/it] 17%|█▋        | 86/498 [24:56<1:59:22, 17.38s/it] 17%|█▋        | 87/498 [25:13<1:59:10, 17.40s/it] 18%|█▊        | 88/498 [25:30<1:58:38, 17.36s/it] 18%|█▊        | 89/498 [25:48<1:58:10, 17.34s/it] 18%|█▊        | 90/498 [26:05<1:57:47, 17.32s/it]                                                  {'loss': 2.5994, 'grad_norm': 2.160525321960449, 'learning_rate': 0.00019110065379230289, 'num_tokens': 2775297.0, 'mean_token_accuracy': 0.4641666755080223, 'epoch': 0.54}
 18%|█▊        | 90/498 [26:05<1:57:47, 17.32s/it] 18%|█▊        | 91/498 [26:22<1:57:45, 17.36s/it] 18%|█▊        | 92/498 [26:40<1:57:39, 17.39s/it] 19%|█▊        | 93/498 [26:57<1:57:11, 17.36s/it] 19%|█▉        | 94/498 [27:14<1:56:46, 17.34s/it] 19%|█▉        | 95/498 [27:32<1:56:42, 17.38s/it] 19%|█▉        | 96/498 [27:49<1:56:53, 17.45s/it] 19%|█▉        | 97/498 [28:07<1:56:35, 17.45s/it] 20%|█▉        | 98/498 [28:24<1:55:38, 17.35s/it] 20%|█▉        | 99/498 [28:41<1:55:32, 17.37s/it] 20%|██        | 100/498 [28:59<1:55:40, 17.44s/it]                                                   {'loss': 2.5899, 'grad_norm': 2.258070945739746, 'learning_rate': 0.00018816275673947148, 'num_tokens': 3083648.0, 'mean_token_accuracy': 0.4741666726768017, 'epoch': 0.6}
 20%|██        | 100/498 [28:59<1:55:40, 17.44s/it] 20%|██        | 101/498 [29:16<1:55:01, 17.39s/it] 20%|██        | 102/498 [29:33<1:54:28, 17.34s/it] 21%|██        | 103/498 [29:51<1:53:40, 17.27s/it] 21%|██        | 104/498 [30:08<1:53:19, 17.26s/it] 21%|██        | 105/498 [30:25<1:52:59, 17.25s/it] 21%|██▏       | 106/498 [30:42<1:52:40, 17.24s/it] 21%|██▏       | 107/498 [30:59<1:52:19, 17.24s/it] 22%|██▏       | 108/498 [31:17<1:51:57, 17.23s/it] 22%|██▏       | 109/498 [31:34<1:51:51, 17.25s/it] 22%|██▏       | 110/498 [31:51<1:51:24, 17.23s/it]                                                   {'loss': 2.5123, 'grad_norm': 2.3449885845184326, 'learning_rate': 0.0001848360805371544, 'num_tokens': 3392028.0, 'mean_token_accuracy': 0.4750000059604645, 'epoch': 0.66}
 22%|██▏       | 110/498 [31:51<1:51:24, 17.23s/it] 22%|██▏       | 111/498 [32:08<1:51:01, 17.21s/it] 22%|██▏       | 112/498 [32:25<1:50:22, 17.16s/it] 23%|██▎       | 113/498 [32:43<1:50:25, 17.21s/it] 23%|██▎       | 114/498 [33:00<1:49:45, 17.15s/it] 23%|██▎       | 115/498 [33:17<1:49:28, 17.15s/it] 23%|██▎       | 116/498 [33:34<1:49:47, 17.24s/it] 23%|██▎       | 117/498 [33:52<1:50:13, 17.36s/it] 24%|██▎       | 118/498 [34:09<1:49:33, 17.30s/it] 24%|██▍       | 119/498 [34:27<1:49:55, 17.40s/it] 24%|██▍       | 120/498 [34:44<1:49:30, 17.38s/it]                                                   {'loss': 2.5462, 'grad_norm': 2.1233959197998047, 'learning_rate': 0.0001811352951252717, 'num_tokens': 3700394.0, 'mean_token_accuracy': 0.4533333420753479, 'epoch': 0.72}
 24%|██▍       | 120/498 [34:44<1:49:30, 17.38s/it] 24%|██▍       | 121/498 [35:01<1:48:51, 17.33s/it] 24%|██▍       | 122/498 [35:19<1:48:39, 17.34s/it] 25%|██▍       | 123/498 [35:36<1:48:27, 17.35s/it] 25%|██▍       | 124/498 [35:54<1:48:33, 17.42s/it] 25%|██▌       | 125/498 [36:11<1:47:58, 17.37s/it] 25%|██▌       | 126/498 [36:28<1:47:46, 17.38s/it] 26%|██▌       | 127/498 [36:46<1:47:15, 17.35s/it] 26%|██▌       | 128/498 [37:03<1:47:05, 17.37s/it] 26%|██▌       | 129/498 [37:20<1:46:36, 17.34s/it] 26%|██▌       | 130/498 [37:38<1:46:29, 17.36s/it]                                                   {'loss': 2.5469, 'grad_norm': 1.8120343685150146, 'learning_rate': 0.00017707672018639758, 'num_tokens': 4008765.0, 'mean_token_accuracy': 0.45750000774860383, 'epoch': 0.78}
 26%|██▌       | 130/498 [37:38<1:46:29, 17.36s/it] 26%|██▋       | 131/498 [37:55<1:45:44, 17.29s/it] 27%|██▋       | 132/498 [38:12<1:45:43, 17.33s/it] 27%|██▋       | 133/498 [38:30<1:45:37, 17.36s/it] 27%|██▋       | 134/498 [38:47<1:45:09, 17.33s/it] 27%|██▋       | 135/498 [39:04<1:45:19, 17.41s/it] 27%|██▋       | 136/498 [39:22<1:45:02, 17.41s/it] 28%|██▊       | 137/498 [39:39<1:44:11, 17.32s/it] 28%|██▊       | 138/498 [39:57<1:44:22, 17.39s/it] 28%|██▊       | 139/498 [40:14<1:44:08, 17.40s/it] 28%|██▊       | 140/498 [40:31<1:43:34, 17.36s/it]                                                   {'loss': 2.5609, 'grad_norm': 1.9526503086090088, 'learning_rate': 0.00017267825317940493, 'num_tokens': 4317139.0, 'mean_token_accuracy': 0.46951150000095365, 'epoch': 0.84}
 28%|██▊       | 140/498 [40:31<1:43:34, 17.36s/it] 28%|██▊       | 141/498 [40:49<1:43:39, 17.42s/it] 29%|██▊       | 142/498 [41:06<1:42:46, 17.32s/it] 29%|██▊       | 143/498 [41:23<1:42:21, 17.30s/it] 29%|██▉       | 144/498 [41:41<1:42:33, 17.38s/it] 29%|██▉       | 145/498 [41:58<1:41:46, 17.30s/it] 29%|██▉       | 146/498 [42:15<1:41:42, 17.34s/it] 30%|██▉       | 147/498 [42:33<1:41:17, 17.31s/it] 30%|██▉       | 148/498 [42:50<1:41:10, 17.34s/it] 30%|██▉       | 149/498 [43:07<1:40:59, 17.36s/it] 30%|███       | 150/498 [43:25<1:40:29, 17.33s/it]                                                   {'loss': 2.5331, 'grad_norm': 1.963308572769165, 'learning_rate': 0.0001679592904154489, 'num_tokens': 4625498.0, 'mean_token_accuracy': 0.46416667513549326, 'epoch': 0.9}
 30%|███       | 150/498 [43:25<1:40:29, 17.33s/it] 30%|███       | 151/498 [43:42<1:40:02, 17.30s/it] 31%|███       | 152/498 [43:59<1:40:11, 17.37s/it] 31%|███       | 153/498 [44:16<1:39:24, 17.29s/it] 31%|███       | 154/498 [44:34<1:39:02, 17.28s/it] 31%|███       | 155/498 [44:51<1:38:59, 17.32s/it] 31%|███▏      | 156/498 [45:09<1:38:51, 17.34s/it] 32%|███▏      | 157/498 [45:26<1:38:39, 17.36s/it] 32%|███▏      | 158/498 [45:43<1:38:26, 17.37s/it] 32%|███▏      | 159/498 [46:01<1:37:54, 17.33s/it] 32%|███▏      | 160/498 [46:18<1:38:14, 17.44s/it]                                                   {'loss': 2.598, 'grad_norm': 2.251603364944458, 'learning_rate': 0.00016294064152432879, 'num_tokens': 4933869.0, 'mean_token_accuracy': 0.46750000640749934, 'epoch': 0.96}
 32%|███▏      | 160/498 [46:18<1:38:14, 17.44s/it] 32%|███▏      | 161/498 [46:35<1:37:36, 17.38s/it] 33%|███▎      | 162/498 [46:53<1:37:37, 17.43s/it] 33%|███▎      | 163/498 [47:11<1:37:32, 17.47s/it] 33%|███▎      | 164/498 [47:28<1:36:52, 17.40s/it] 33%|███▎      | 165/498 [47:45<1:36:50, 17.45s/it] 33%|███▎      | 166/498 [48:03<1:36:13, 17.39s/it] 34%|███▎      | 167/498 [48:14<1:26:21, 15.65s/it] 34%|███▎      | 168/498 [48:33<1:30:27, 16.45s/it] 34%|███▍      | 169/498 [48:50<1:31:44, 16.73s/it] 34%|███▍      | 170/498 [49:07<1:32:32, 16.93s/it]                                                   {'loss': 2.3413, 'grad_norm': 1.5669716596603394, 'learning_rate': 0.00015764443768841234, 'num_tokens': 5231934.0, 'mean_token_accuracy': 0.49572650400491863, 'epoch': 1.02}
 34%|███▍      | 170/498 [49:07<1:32:32, 16.93s/it] 34%|███▍      | 171/498 [49:25<1:33:00, 17.07s/it] 35%|███▍      | 172/498 [49:42<1:32:58, 17.11s/it] 35%|███▍      | 173/498 [49:59<1:33:06, 17.19s/it] 35%|███▍      | 174/498 [50:17<1:33:37, 17.34s/it] 35%|███▌      | 175/498 [50:34<1:32:52, 17.25s/it] 35%|███▌      | 176/498 [50:52<1:33:01, 17.33s/it] 36%|███▌      | 177/498 [51:09<1:32:46, 17.34s/it] 36%|███▌      | 178/498 [51:26<1:32:15, 17.30s/it] 36%|███▌      | 179/498 [51:44<1:32:05, 17.32s/it] 36%|███▌      | 180/498 [52:01<1:31:52, 17.34s/it]                                                   {'loss': 1.9482, 'grad_norm': 1.813886046409607, 'learning_rate': 0.00015209403404879303, 'num_tokens': 5540297.0, 'mean_token_accuracy': 0.5622701212763787, 'epoch': 1.08}
 36%|███▌      | 180/498 [52:01<1:31:52, 17.34s/it] 36%|███▋      | 181/498 [52:18<1:31:53, 17.39s/it] 37%|███▋      | 182/498 [52:36<1:31:17, 17.33s/it] 37%|███▋      | 183/498 [52:53<1:31:01, 17.34s/it] 37%|███▋      | 184/498 [53:10<1:30:16, 17.25s/it] 37%|███▋      | 185/498 [53:27<1:29:39, 17.19s/it] 37%|███▋      | 186/498 [53:45<1:29:53, 17.29s/it] 38%|███▊      | 187/498 [54:02<1:29:29, 17.26s/it] 38%|███▊      | 188/498 [54:19<1:29:22, 17.30s/it] 38%|███▊      | 189/498 [54:37<1:29:27, 17.37s/it] 38%|███▊      | 190/498 [54:54<1:29:10, 17.37s/it]                                                   {'loss': 2.1024, 'grad_norm': 3.125330924987793, 'learning_rate': 0.0001463139067140468, 'num_tokens': 5848661.0, 'mean_token_accuracy': 0.5333333395421505, 'epoch': 1.14}
 38%|███▊      | 190/498 [54:54<1:29:10, 17.37s/it] 38%|███▊      | 191/498 [55:11<1:28:24, 17.28s/it] 39%|███▊      | 192/498 [55:29<1:28:29, 17.35s/it] 39%|███▉      | 193/498 [55:46<1:27:59, 17.31s/it] 39%|███▉      | 194/498 [56:04<1:28:16, 17.42s/it] 39%|███▉      | 195/498 [56:21<1:27:55, 17.41s/it] 39%|███▉      | 196/498 [56:38<1:27:49, 17.45s/it] 40%|███▉      | 197/498 [56:56<1:27:12, 17.38s/it] 40%|███▉      | 198/498 [57:13<1:26:55, 17.38s/it] 40%|███▉      | 199/498 [57:30<1:26:24, 17.34s/it] 40%|████      | 200/498 [57:48<1:25:58, 17.31s/it]                                                   {'loss': 2.054, 'grad_norm': 2.457829713821411, 'learning_rate': 0.00014032954482575937, 'num_tokens': 6157029.0, 'mean_token_accuracy': 0.5408333383500576, 'epoch': 1.2}
 40%|████      | 200/498 [57:48<1:25:58, 17.31s/it] 40%|████      | 201/498 [58:05<1:25:49, 17.34s/it] 41%|████      | 202/498 [58:22<1:25:25, 17.31s/it] 41%|████      | 203/498 [58:40<1:25:16, 17.34s/it] 41%|████      | 204/498 [58:57<1:25:04, 17.36s/it] 41%|████      | 205/498 [59:14<1:24:51, 17.38s/it] 41%|████▏     | 206/498 [59:32<1:24:22, 17.34s/it] 42%|████▏     | 207/498 [59:49<1:24:26, 17.41s/it] 42%|████▏     | 208/498 [1:00:07<1:23:55, 17.36s/it] 42%|████▏     | 209/498 [1:00:24<1:23:42, 17.38s/it] 42%|████▏     | 210/498 [1:00:41<1:23:26, 17.38s/it]                                                     {'loss': 1.9083, 'grad_norm': 3.0166728496551514, 'learning_rate': 0.00013416733815679166, 'num_tokens': 6465391.0, 'mean_token_accuracy': 0.5883333362638951, 'epoch': 1.26}
 42%|████▏     | 210/498 [1:00:41<1:23:26, 17.38s/it] 42%|████▏     | 211/498 [1:00:59<1:22:56, 17.34s/it] 43%|████▎     | 212/498 [1:01:16<1:22:43, 17.35s/it] 43%|████▎     | 213/498 [1:01:33<1:22:15, 17.32s/it] 43%|████▎     | 214/498 [1:01:50<1:21:38, 17.25s/it] 43%|████▎     | 215/498 [1:02:07<1:21:06, 17.20s/it] 43%|████▎     | 216/498 [1:02:25<1:21:07, 17.26s/it] 44%|████▎     | 217/498 [1:02:42<1:20:48, 17.25s/it] 44%|████▍     | 218/498 [1:02:59<1:20:42, 17.30s/it] 44%|████▍     | 219/498 [1:03:17<1:20:18, 17.27s/it] 44%|████▍     | 220/498 [1:03:34<1:20:35, 17.39s/it]                                                     {'loss': 1.9533, 'grad_norm': 3.457355499267578, 'learning_rate': 0.00012785446073795118, 'num_tokens': 6773768.0, 'mean_token_accuracy': 0.5575000070035457, 'epoch': 1.32}
 44%|████▍     | 220/498 [1:03:34<1:20:35, 17.39s/it] 44%|████▍     | 221/498 [1:03:52<1:20:42, 17.48s/it] 45%|████▍     | 222/498 [1:04:10<1:20:42, 17.54s/it] 45%|████▍     | 223/498 [1:04:27<1:20:23, 17.54s/it] 45%|████▍     | 224/498 [1:04:44<1:19:38, 17.44s/it] 45%|████▌     | 225/498 [1:05:01<1:18:48, 17.32s/it] 45%|████▌     | 226/498 [1:05:19<1:18:48, 17.38s/it] 46%|████▌     | 227/498 [1:05:36<1:18:16, 17.33s/it] 46%|████▌     | 228/498 [1:05:53<1:17:49, 17.29s/it] 46%|████▌     | 229/498 [1:06:11<1:17:26, 17.27s/it] 46%|████▌     | 230/498 [1:06:28<1:17:04, 17.26s/it]                                                     {'loss': 1.8297, 'grad_norm': 4.098771572113037, 'learning_rate': 0.00012141875102625167, 'num_tokens': 7082129.0, 'mean_token_accuracy': 0.5833333432674408, 'epoch': 1.38}
 46%|████▌     | 230/498 [1:06:28<1:17:04, 17.26s/it] 46%|████▋     | 231/498 [1:06:45<1:16:58, 17.30s/it] 47%|████▋     | 232/498 [1:07:02<1:16:36, 17.28s/it] 47%|████▋     | 233/498 [1:07:20<1:16:41, 17.37s/it] 47%|████▋     | 234/498 [1:07:37<1:16:01, 17.28s/it] 47%|████▋     | 235/498 [1:07:55<1:15:54, 17.32s/it] 47%|████▋     | 236/498 [1:08:12<1:15:43, 17.34s/it] 48%|████▊     | 237/498 [1:08:29<1:15:30, 17.36s/it] 48%|████▊     | 238/498 [1:08:47<1:15:15, 17.37s/it] 48%|████▊     | 239/498 [1:09:04<1:14:49, 17.33s/it] 48%|████▊     | 240/498 [1:09:21<1:14:37, 17.36s/it]                                                     {'loss': 1.9313, 'grad_norm': 3.4441022872924805, 'learning_rate': 0.0001148885891431932, 'num_tokens': 7390501.0, 'mean_token_accuracy': 0.5608333431184291, 'epoch': 1.44}
 48%|████▊     | 240/498 [1:09:21<1:14:37, 17.36s/it] 48%|████▊     | 241/498 [1:09:39<1:14:11, 17.32s/it] 49%|████▊     | 242/498 [1:09:56<1:14:01, 17.35s/it] 49%|████▉     | 243/498 [1:10:14<1:14:03, 17.43s/it] 49%|████▉     | 244/498 [1:10:31<1:13:45, 17.43s/it] 49%|████▉     | 245/498 [1:10:49<1:13:40, 17.47s/it] 49%|████▉     | 246/498 [1:11:06<1:13:43, 17.55s/it] 50%|████▉     | 247/498 [1:11:24<1:13:29, 17.57s/it] 50%|████▉     | 248/498 [1:11:41<1:13:01, 17.53s/it] 50%|█████     | 249/498 [1:11:59<1:12:47, 17.54s/it] 50%|█████     | 250/498 [1:12:16<1:12:20, 17.50s/it]                                                     {'loss': 1.9129, 'grad_norm': 2.897040843963623, 'learning_rate': 0.00010829277172441648, 'num_tokens': 7698860.0, 'mean_token_accuracy': 0.5641666747629642, 'epoch': 1.5}
 50%|█████     | 250/498 [1:12:16<1:12:20, 17.50s/it] 50%|█████     | 251/498 [1:12:34<1:12:07, 17.52s/it] 51%|█████     | 252/498 [1:12:51<1:11:29, 17.44s/it] 51%|█████     | 253/498 [1:13:09<1:11:08, 17.42s/it] 51%|█████     | 254/498 [1:13:26<1:10:49, 17.42s/it] 51%|█████     | 255/498 [1:13:43<1:10:31, 17.41s/it] 51%|█████▏    | 256/498 [1:14:01<1:10:12, 17.41s/it] 52%|█████▏    | 257/498 [1:14:18<1:09:41, 17.35s/it] 52%|█████▏    | 258/498 [1:14:35<1:09:03, 17.27s/it] 52%|█████▏    | 259/498 [1:14:53<1:09:06, 17.35s/it] 52%|█████▏    | 260/498 [1:15:10<1:08:39, 17.31s/it]                                                     {'loss': 1.9523, 'grad_norm': 3.7365667819976807, 'learning_rate': 0.00010166038493261722, 'num_tokens': 8007228.0, 'mean_token_accuracy': 0.5641666747629642, 'epoch': 1.56}
 52%|█████▏    | 260/498 [1:15:10<1:08:39, 17.31s/it] 52%|█████▏    | 261/498 [1:15:27<1:08:17, 17.29s/it] 53%|█████▎    | 262/498 [1:15:44<1:07:44, 17.22s/it] 53%|█████▎    | 263/498 [1:16:01<1:07:28, 17.23s/it] 53%|█████▎    | 264/498 [1:16:19<1:07:22, 17.28s/it] 53%|█████▎    | 265/498 [1:16:36<1:07:02, 17.26s/it] 53%|█████▎    | 266/498 [1:16:53<1:06:53, 17.30s/it] 54%|█████▎    | 267/498 [1:17:10<1:06:19, 17.23s/it] 54%|█████▍    | 268/498 [1:17:28<1:06:12, 17.27s/it] 54%|█████▍    | 269/498 [1:17:45<1:05:52, 17.26s/it] 54%|█████▍    | 270/498 [1:18:02<1:05:32, 17.25s/it]                                                     {'loss': 1.8339, 'grad_norm': 4.096128940582275, 'learning_rate': 9.502067619370794e-05, 'num_tokens': 8315612.0, 'mean_token_accuracy': 0.5666666746139526, 'epoch': 1.62}
 54%|█████▍    | 270/498 [1:18:02<1:05:32, 17.25s/it] 54%|█████▍    | 271/498 [1:18:19<1:05:13, 17.24s/it] 55%|█████▍    | 272/498 [1:18:37<1:05:15, 17.33s/it] 55%|█████▍    | 273/498 [1:18:55<1:05:12, 17.39s/it] 55%|█████▌    | 274/498 [1:19:12<1:05:04, 17.43s/it] 55%|█████▌    | 275/498 [1:19:29<1:04:43, 17.41s/it] 55%|█████▌    | 276/498 [1:19:47<1:04:11, 17.35s/it] 56%|█████▌    | 277/498 [1:20:04<1:03:34, 17.26s/it] 56%|█████▌    | 278/498 [1:20:21<1:03:24, 17.29s/it] 56%|█████▌    | 279/498 [1:20:38<1:03:13, 17.32s/it] 56%|█████▌    | 280/498 [1:20:56<1:03:10, 17.39s/it]                                                     {'loss': 1.9404, 'grad_norm': 3.3989691734313965, 'learning_rate': 8.840292522184247e-05, 'num_tokens': 8623982.0, 'mean_token_accuracy': 0.5833333402872085, 'epoch': 1.68}
 56%|█████▌    | 280/498 [1:20:56<1:03:10, 17.39s/it] 56%|█████▋    | 281/498 [1:21:13<1:02:52, 17.38s/it] 57%|█████▋    | 282/498 [1:21:31<1:02:35, 17.38s/it] 57%|█████▋    | 283/498 [1:21:48<1:02:28, 17.43s/it] 57%|█████▋    | 284/498 [1:22:06<1:02:07, 17.42s/it] 57%|█████▋    | 285/498 [1:22:23<1:01:59, 17.46s/it] 57%|█████▋    | 286/498 [1:22:41<1:01:57, 17.53s/it] 58%|█████▊    | 287/498 [1:22:58<1:01:20, 17.44s/it] 58%|█████▊    | 288/498 [1:23:15<1:00:50, 17.38s/it] 58%|█████▊    | 289/498 [1:23:33<1:00:34, 17.39s/it] 58%|█████▊    | 290/498 [1:23:50<59:59, 17.31s/it]                                                     {'loss': 1.8385, 'grad_norm': 4.911291122436523, 'learning_rate': 8.183631490205637e-05, 'num_tokens': 8932334.0, 'mean_token_accuracy': 0.589166671037674, 'epoch': 1.74}
 58%|█████▊    | 290/498 [1:23:50<59:59, 17.31s/it] 58%|█████▊    | 291/498 [1:24:07<59:49, 17.34s/it] 59%|█████▊    | 292/498 [1:24:25<59:36, 17.36s/it] 59%|█████▉    | 293/498 [1:24:42<59:22, 17.38s/it] 59%|█████▉    | 294/498 [1:25:00<59:16, 17.43s/it] 59%|█████▉    | 295/498 [1:25:17<59:06, 17.47s/it] 59%|█████▉    | 296/498 [1:25:35<58:43, 17.44s/it] 60%|█████▉    | 297/498 [1:25:52<58:13, 17.38s/it] 60%|█████▉    | 298/498 [1:26:09<57:47, 17.34s/it] 60%|██████    | 299/498 [1:26:26<57:15, 17.26s/it] 60%|██████    | 300/498 [1:26:44<57:15, 17.35s/it]                                                   {'loss': 1.8641, 'grad_norm': 3.4242162704467773, 'learning_rate': 7.534980259990341e-05, 'num_tokens': 9240697.0, 'mean_token_accuracy': 0.59500000923872, 'epoch': 1.8}
 60%|██████    | 300/498 [1:26:44<57:15, 17.35s/it] 60%|██████    | 301/498 [1:27:01<57:01, 17.37s/it] 61%|██████    | 302/498 [1:27:18<56:27, 17.28s/it] 61%|██████    | 303/498 [1:27:36<56:15, 17.31s/it] 61%|██████    | 304/498 [1:27:53<56:10, 17.37s/it] 61%|██████    | 305/498 [1:28:11<55:52, 17.37s/it] 61%|██████▏   | 306/498 [1:28:28<55:53, 17.47s/it] 62%|██████▏   | 307/498 [1:28:45<55:21, 17.39s/it] 62%|██████▏   | 308/498 [1:29:03<55:04, 17.39s/it] 62%|██████▏   | 309/498 [1:29:20<54:47, 17.40s/it] 62%|██████▏   | 310/498 [1:29:38<54:31, 17.40s/it]                                                   {'loss': 1.7912, 'grad_norm': 3.7675299644470215, 'learning_rate': 6.897199246558514e-05, 'num_tokens': 9549061.0, 'mean_token_accuracy': 0.5966666765511036, 'epoch': 1.86}
 62%|██████▏   | 310/498 [1:29:38<54:31, 17.40s/it] 62%|██████▏   | 311/498 [1:29:55<54:23, 17.45s/it] 63%|██████▎   | 312/498 [1:30:13<54:12, 17.49s/it] 63%|██████▎   | 313/498 [1:30:30<53:42, 17.42s/it] 63%|██████▎   | 314/498 [1:30:47<53:24, 17.42s/it] 63%|██████▎   | 315/498 [1:31:05<52:59, 17.37s/it] 63%|██████▎   | 316/498 [1:31:22<52:35, 17.34s/it] 64%|██████▎   | 317/498 [1:31:39<52:13, 17.31s/it] 64%|██████▍   | 318/498 [1:31:56<51:44, 17.25s/it] 64%|██████▍   | 319/498 [1:32:14<51:35, 17.29s/it] 64%|██████▍   | 320/498 [1:32:31<51:23, 17.32s/it]                                                   {'loss': 1.8427, 'grad_norm': 6.085897445678711, 'learning_rate': 6.273100929568578e-05, 'num_tokens': 9857426.0, 'mean_token_accuracy': 0.5729310415685177, 'epoch': 1.92}
 64%|██████▍   | 320/498 [1:32:31<51:23, 17.32s/it] 64%|██████▍   | 321/498 [1:32:48<51:01, 17.30s/it] 65%|██████▍   | 322/498 [1:33:06<50:49, 17.32s/it] 65%|██████▍   | 323/498 [1:33:23<50:43, 17.39s/it] 65%|██████▌   | 324/498 [1:33:41<50:25, 17.39s/it] 65%|██████▌   | 325/498 [1:33:58<50:00, 17.34s/it] 65%|██████▌   | 326/498 [1:34:15<49:28, 17.26s/it] 66%|██████▌   | 327/498 [1:34:33<49:25, 17.34s/it] 66%|██████▌   | 328/498 [1:34:50<49:17, 17.39s/it] 66%|██████▌   | 329/498 [1:35:07<48:42, 17.30s/it] 66%|██████▋   | 330/498 [1:35:25<48:30, 17.32s/it]                                                   {'loss': 1.9387, 'grad_norm': 4.011085510253906, 'learning_rate': 5.665437450875534e-05, 'num_tokens': 10165802.0, 'mean_token_accuracy': 0.5591666728258133, 'epoch': 1.98}
 66%|██████▋   | 330/498 [1:35:25<48:30, 17.32s/it] 66%|██████▋   | 331/498 [1:35:42<48:24, 17.39s/it] 67%|██████▋   | 332/498 [1:35:59<47:59, 17.34s/it] 67%|██████▋   | 333/498 [1:36:16<47:28, 17.27s/it] 67%|██████▋   | 334/498 [1:36:28<42:40, 15.61s/it] 67%|██████▋   | 335/498 [1:36:47<44:59, 16.56s/it] 67%|██████▋   | 336/498 [1:37:04<45:23, 16.81s/it] 68%|██████▊   | 337/498 [1:37:22<45:34, 16.99s/it] 68%|██████▊   | 338/498 [1:37:39<45:37, 17.11s/it] 68%|██████▊   | 339/498 [1:37:57<45:41, 17.24s/it] 68%|██████▊   | 340/498 [1:38:14<45:39, 17.34s/it]                                                   {'loss': 1.5577, 'grad_norm': 3.1232614517211914, 'learning_rate': 5.0768884781662465e-05, 'num_tokens': 10463892.0, 'mean_token_accuracy': 0.6521367552952889, 'epoch': 2.04}
 68%|██████▊   | 340/498 [1:38:14<45:39, 17.34s/it] 68%|██████▊   | 341/498 [1:38:32<45:32, 17.40s/it] 69%|██████▊   | 342/498 [1:38:49<45:06, 17.35s/it] 69%|██████▉   | 343/498 [1:39:06<44:50, 17.36s/it] 69%|██████▉   | 344/498 [1:39:24<44:26, 17.31s/it] 69%|██████▉   | 345/498 [1:39:41<44:11, 17.33s/it] 69%|██████▉   | 346/498 [1:39:58<43:56, 17.34s/it] 70%|██████▉   | 347/498 [1:40:16<43:33, 17.31s/it] 70%|██████▉   | 348/498 [1:40:33<43:19, 17.33s/it] 70%|███████   | 349/498 [1:40:50<42:52, 17.26s/it] 70%|███████   | 350/498 [1:41:07<42:41, 17.31s/it]                                                   {'loss': 1.1582, 'grad_norm': 5.2944536209106445, 'learning_rate': 4.510049388190518e-05, 'num_tokens': 10772248.0, 'mean_token_accuracy': 0.7233333341777325, 'epoch': 2.1}
 70%|███████   | 350/498 [1:41:07<42:41, 17.31s/it] 70%|███████   | 351/498 [1:41:25<42:21, 17.29s/it] 71%|███████   | 352/498 [1:41:42<42:09, 17.33s/it] 71%|███████   | 353/498 [1:42:00<41:55, 17.35s/it] 71%|███████   | 354/498 [1:42:17<41:54, 17.46s/it] 71%|███████▏  | 355/498 [1:42:34<41:27, 17.40s/it] 71%|███████▏  | 356/498 [1:42:52<41:17, 17.44s/it] 72%|███████▏  | 357/498 [1:43:09<40:57, 17.43s/it] 72%|███████▏  | 358/498 [1:43:27<40:31, 17.37s/it] 72%|███████▏  | 359/498 [1:43:44<40:01, 17.28s/it] 72%|███████▏  | 360/498 [1:44:01<39:47, 17.30s/it]                                                   {'loss': 1.1467, 'grad_norm': 4.961704254150391, 'learning_rate': 3.96741982169742e-05, 'num_tokens': 11080607.0, 'mean_token_accuracy': 0.7425000011920929, 'epoch': 2.16}
 72%|███████▏  | 360/498 [1:44:01<39:47, 17.30s/it] 72%|███████▏  | 361/498 [1:44:18<39:26, 17.27s/it] 73%|███████▎  | 362/498 [1:44:36<39:12, 17.30s/it] 73%|███████▎  | 363/498 [1:44:53<39:04, 17.37s/it] 73%|███████▎  | 364/498 [1:45:10<38:40, 17.32s/it] 73%|███████▎  | 365/498 [1:45:27<38:12, 17.24s/it] 73%|███████▎  | 366/498 [1:45:45<38:06, 17.32s/it] 74%|███████▎  | 367/498 [1:46:02<37:38, 17.24s/it] 74%|███████▍  | 368/498 [1:46:19<37:19, 17.23s/it] 74%|███████▍  | 369/498 [1:46:37<37:13, 17.32s/it] 74%|███████▍  | 370/498 [1:46:54<36:52, 17.28s/it]                                                   {'loss': 1.1516, 'grad_norm': 4.107966423034668, 'learning_rate': 3.45139266054715e-05, 'num_tokens': 11388982.0, 'mean_token_accuracy': 0.7200000017881394, 'epoch': 2.22}
 74%|███████▍  | 370/498 [1:46:54<36:52, 17.28s/it] 74%|███████▍  | 371/498 [1:47:11<36:44, 17.36s/it] 75%|███████▍  | 372/498 [1:47:29<36:33, 17.41s/it] 75%|███████▍  | 373/498 [1:47:46<36:14, 17.40s/it] 75%|███████▌  | 374/498 [1:48:04<36:02, 17.44s/it] 75%|███████▌  | 375/498 [1:48:21<35:42, 17.42s/it] 76%|███████▌  | 376/498 [1:48:38<35:17, 17.36s/it] 76%|███████▌  | 377/498 [1:48:56<34:54, 17.31s/it] 76%|███████▌  | 378/498 [1:49:13<34:38, 17.32s/it] 76%|███████▌  | 379/498 [1:49:30<34:17, 17.29s/it] 76%|███████▋  | 380/498 [1:49:48<34:02, 17.31s/it]                                                   {'loss': 1.0545, 'grad_norm': 4.642698287963867, 'learning_rate': 2.9642434756070793e-05, 'num_tokens': 11697343.0, 'mean_token_accuracy': 0.7450000032782554, 'epoch': 2.28}
 76%|███████▋  | 380/498 [1:49:48<34:02, 17.31s/it] 77%|███████▋  | 381/498 [1:50:05<33:35, 17.23s/it] 77%|███████▋  | 382/498 [1:50:22<33:22, 17.26s/it] 77%|███████▋  | 383/498 [1:50:39<33:02, 17.24s/it] 77%|███████▋  | 384/498 [1:50:57<32:49, 17.27s/it] 77%|███████▋  | 385/498 [1:51:14<32:34, 17.30s/it] 78%|███████▊  | 386/498 [1:51:31<32:24, 17.36s/it] 78%|███████▊  | 387/498 [1:51:49<32:06, 17.36s/it] 78%|███████▊  | 388/498 [1:52:06<31:49, 17.36s/it] 78%|███████▊  | 389/498 [1:52:23<31:27, 17.32s/it] 78%|███████▊  | 390/498 [1:52:41<31:12, 17.34s/it]                                                   {'loss': 1.1023, 'grad_norm': 5.69619607925415, 'learning_rate': 2.508120491964512e-05, 'num_tokens': 12005720.0, 'mean_token_accuracy': 0.7391666665673255, 'epoch': 2.34}
 78%|███████▊  | 390/498 [1:52:41<31:12, 17.34s/it] 79%|███████▊  | 391/498 [1:52:58<30:56, 17.35s/it] 79%|███████▊  | 392/498 [1:53:15<30:28, 17.25s/it] 79%|███████▉  | 393/498 [1:53:32<30:14, 17.28s/it] 79%|███████▉  | 394/498 [1:53:49<29:49, 17.21s/it] 79%|███████▉  | 395/498 [1:54:07<29:32, 17.21s/it] 80%|███████▉  | 396/498 [1:54:24<29:14, 17.20s/it] 80%|███████▉  | 397/498 [1:54:41<29:07, 17.30s/it] 80%|███████▉  | 398/498 [1:54:59<29:01, 17.41s/it] 80%|████████  | 399/498 [1:55:16<28:42, 17.39s/it] 80%|████████  | 400/498 [1:55:34<28:28, 17.43s/it]                                                   {'loss': 1.0164, 'grad_norm': 4.787274360656738, 'learning_rate': 2.0850351157074598e-05, 'num_tokens': 12314072.0, 'mean_token_accuracy': 0.7449999988079071, 'epoch': 2.4}
 80%|████████  | 400/498 [1:55:34<28:28, 17.43s/it] 81%|████████  | 401/498 [1:55:51<28:04, 17.36s/it] 81%|████████  | 402/498 [1:56:08<27:41, 17.31s/it] 81%|████████  | 403/498 [1:56:26<27:21, 17.27s/it] 81%|████████  | 404/498 [1:56:43<27:01, 17.25s/it] 81%|████████▏ | 405/498 [1:57:00<26:42, 17.23s/it] 82%|████████▏ | 406/498 [1:57:17<26:24, 17.22s/it] 82%|████████▏ | 407/498 [1:57:34<26:01, 17.16s/it] 82%|████████▏ | 408/498 [1:57:51<25:41, 17.13s/it] 82%|████████▏ | 409/498 [1:58:09<25:39, 17.30s/it] 82%|████████▏ | 410/498 [1:58:26<25:24, 17.32s/it]                                                   {'loss': 1.068, 'grad_norm': 4.7278876304626465, 'learning_rate': 1.6968530640483127e-05, 'num_tokens': 12622459.0, 'mean_token_accuracy': 0.7374999985098839, 'epoch': 2.46}
 82%|████████▏ | 410/498 [1:58:26<25:24, 17.32s/it] 83%|████████▎ | 411/498 [1:58:44<25:08, 17.34s/it] 83%|████████▎ | 412/498 [1:59:01<24:48, 17.30s/it] 83%|████████▎ | 413/498 [1:59:18<24:32, 17.33s/it] 83%|████████▎ | 414/498 [1:59:36<24:20, 17.39s/it] 83%|████████▎ | 415/498 [1:59:53<23:55, 17.30s/it] 84%|████████▎ | 416/498 [2:00:10<23:40, 17.33s/it] 84%|████████▎ | 417/498 [2:00:27<23:21, 17.30s/it] 84%|████████▍ | 418/498 [2:00:45<23:10, 17.38s/it] 84%|████████▍ | 419/498 [2:01:03<22:57, 17.43s/it] 84%|████████▍ | 420/498 [2:01:20<22:46, 17.52s/it]                                                   {'loss': 1.0287, 'grad_norm': 6.233700752258301, 'learning_rate': 1.3452861379047287e-05, 'num_tokens': 12930827.0, 'mean_token_accuracy': 0.7541666641831398, 'epoch': 2.52}
 84%|████████▍ | 420/498 [2:01:20<22:46, 17.52s/it] 85%|████████▍ | 421/498 [2:01:38<22:22, 17.43s/it] 85%|████████▍ | 422/498 [2:01:55<22:03, 17.41s/it] 85%|████████▍ | 423/498 [2:02:12<21:44, 17.40s/it] 85%|████████▌ | 424/498 [2:02:30<21:26, 17.38s/it] 85%|████████▌ | 425/498 [2:02:47<21:04, 17.32s/it] 86%|████████▌ | 426/498 [2:03:04<20:47, 17.33s/it] 86%|████████▌ | 427/498 [2:03:22<20:32, 17.36s/it] 86%|████████▌ | 428/498 [2:03:39<20:13, 17.34s/it] 86%|████████▌ | 429/498 [2:03:56<19:58, 17.37s/it] 86%|████████▋ | 430/498 [2:04:13<19:32, 17.24s/it]                                                   {'loss': 1.1088, 'grad_norm': 4.702795505523682, 'learning_rate': 1.0318846732188737e-05, 'num_tokens': 13239182.0, 'mean_token_accuracy': 0.7333333365619182, 'epoch': 2.58}
 86%|████████▋ | 430/498 [2:04:13<19:32, 17.24s/it] 87%|████████▋ | 431/498 [2:04:30<19:12, 17.21s/it] 87%|████████▋ | 432/498 [2:04:48<18:57, 17.23s/it] 87%|████████▋ | 433/498 [2:05:05<18:41, 17.25s/it] 87%|████████▋ | 434/498 [2:05:22<18:25, 17.27s/it] 87%|████████▋ | 435/498 [2:05:39<18:02, 17.19s/it] 88%|████████▊ | 436/498 [2:05:56<17:44, 17.18s/it] 88%|████████▊ | 437/498 [2:06:14<17:30, 17.23s/it] 88%|████████▊ | 438/498 [2:06:31<17:19, 17.32s/it] 88%|████████▊ | 439/498 [2:06:49<17:05, 17.38s/it] 88%|████████▊ | 440/498 [2:07:06<16:50, 17.43s/it]                                                   {'loss': 1.1632, 'grad_norm': 4.924126625061035, 'learning_rate': 7.580307043031232e-06, 'num_tokens': 13547544.0, 'mean_token_accuracy': 0.7208333373069763, 'epoch': 2.64}
 88%|████████▊ | 440/498 [2:07:06<16:50, 17.43s/it] 89%|████████▊ | 441/498 [2:07:24<16:32, 17.41s/it] 89%|████████▉ | 442/498 [2:07:41<16:14, 17.41s/it] 89%|████████▉ | 443/498 [2:07:59<15:56, 17.40s/it] 89%|████████▉ | 444/498 [2:08:16<15:38, 17.39s/it] 89%|████████▉ | 445/498 [2:08:33<15:21, 17.38s/it] 90%|████████▉ | 446/498 [2:08:50<14:58, 17.29s/it] 90%|████████▉ | 447/498 [2:09:08<14:45, 17.36s/it] 90%|████████▉ | 448/498 [2:09:25<14:25, 17.32s/it] 90%|█████████ | 449/498 [2:09:42<14:06, 17.28s/it] 90%|█████████ | 450/498 [2:10:00<13:50, 17.30s/it]                                                   {'loss': 1.1358, 'grad_norm': 5.018771648406982, 'learning_rate': 5.249318693604577e-06, 'num_tokens': 13855919.0, 'mean_token_accuracy': 0.7333333387970924, 'epoch': 2.7}
 90%|█████████ | 450/498 [2:10:00<13:50, 17.30s/it] 91%|█████████ | 451/498 [2:10:17<13:31, 17.27s/it] 91%|█████████ | 452/498 [2:10:34<13:19, 17.38s/it] 91%|█████████ | 453/498 [2:10:52<13:03, 17.42s/it] 91%|█████████ | 454/498 [2:11:09<12:43, 17.34s/it] 91%|█████████▏| 455/498 [2:11:26<12:25, 17.34s/it] 92%|█████████▏| 456/498 [2:11:44<12:08, 17.34s/it] 92%|█████████▏| 457/498 [2:12:01<11:50, 17.34s/it] 92%|█████████▏| 458/498 [2:12:18<11:33, 17.34s/it] 92%|█████████▏| 459/498 [2:12:36<11:16, 17.34s/it] 92%|█████████▏| 460/498 [2:12:53<10:55, 17.24s/it]                                                   {'loss': 1.0011, 'grad_norm': 4.56004524230957, 'learning_rate': 3.33616085054862e-06, 'num_tokens': 14164282.0, 'mean_token_accuracy': 0.7458333313465119, 'epoch': 2.76}
 92%|█████████▏| 460/498 [2:12:53<10:55, 17.24s/it] 93%|█████████▎| 461/498 [2:13:10<10:39, 17.27s/it] 93%|█████████▎| 462/498 [2:13:28<10:22, 17.29s/it] 93%|█████████▎| 463/498 [2:13:45<10:03, 17.25s/it] 93%|█████████▎| 464/498 [2:14:02<09:47, 17.28s/it] 93%|█████████▎| 465/498 [2:14:19<09:31, 17.30s/it] 94%|█████████▎| 466/498 [2:14:37<09:14, 17.32s/it] 94%|█████████▍| 467/498 [2:14:54<08:55, 17.28s/it] 94%|█████████▍| 468/498 [2:15:11<08:36, 17.20s/it] 94%|█████████▍| 469/498 [2:15:28<08:17, 17.15s/it] 94%|█████████▍| 470/498 [2:15:45<08:00, 17.17s/it]                                                   {'loss': 1.0288, 'grad_norm': 4.589123725891113, 'learning_rate': 1.8492701361578324e-06, 'num_tokens': 14472655.0, 'mean_token_accuracy': 0.753333330154419, 'epoch': 2.82}
 94%|█████████▍| 470/498 [2:15:45<08:00, 17.17s/it] 95%|█████████▍| 471/498 [2:16:02<07:43, 17.18s/it] 95%|█████████▍| 472/498 [2:16:20<07:28, 17.23s/it] 95%|█████████▍| 473/498 [2:16:37<07:10, 17.23s/it] 95%|█████████▌| 474/498 [2:16:55<06:55, 17.32s/it] 95%|█████████▌| 475/498 [2:17:12<06:37, 17.28s/it] 96%|█████████▌| 476/498 [2:17:29<06:18, 17.21s/it] 96%|█████████▌| 477/498 [2:17:46<06:01, 17.20s/it] 96%|█████████▌| 478/498 [2:18:03<05:44, 17.23s/it] 96%|█████████▌| 479/498 [2:18:20<05:26, 17.20s/it] 96%|█████████▋| 480/498 [2:18:38<05:10, 17.28s/it]                                                   {'loss': 1.1117, 'grad_norm': 5.332117557525635, 'learning_rate': 7.952034246577977e-07, 'num_tokens': 14781030.0, 'mean_token_accuracy': 0.7408333353698253, 'epoch': 2.88}
 96%|█████████▋| 480/498 [2:18:38<05:10, 17.28s/it] 97%|█████████▋| 481/498 [2:18:55<04:54, 17.33s/it] 97%|█████████▋| 482/498 [2:19:13<04:37, 17.32s/it] 97%|█████████▋| 483/498 [2:19:30<04:18, 17.21s/it] 97%|█████████▋| 484/498 [2:19:47<04:01, 17.24s/it] 97%|█████████▋| 485/498 [2:20:04<03:44, 17.30s/it] 98%|█████████▊| 486/498 [2:20:22<03:28, 17.34s/it] 98%|█████████▊| 487/498 [2:20:39<03:11, 17.37s/it] 98%|█████████▊| 488/498 [2:20:56<02:52, 17.24s/it] 98%|█████████▊| 489/498 [2:21:13<02:34, 17.20s/it] 98%|█████████▊| 490/498 [2:21:30<02:17, 17.17s/it]                                                   {'loss': 1.0671, 'grad_norm': 4.775611877441406, 'learning_rate': 1.7860892777367133e-07, 'num_tokens': 15089396.0, 'mean_token_accuracy': 0.7449999988079071, 'epoch': 2.94}
 98%|█████████▊| 490/498 [2:21:30<02:17, 17.17s/it] 99%|█████████▊| 491/498 [2:21:48<02:00, 17.20s/it] 99%|█████████▉| 492/498 [2:22:05<01:43, 17.21s/it] 99%|█████████▉| 493/498 [2:22:22<01:25, 17.18s/it] 99%|█████████▉| 494/498 [2:22:39<01:09, 17.30s/it] 99%|█████████▉| 495/498 [2:22:57<00:51, 17.29s/it]100%|█████████▉| 496/498 [2:23:14<00:34, 17.29s/it]100%|█████████▉| 497/498 [2:23:31<00:17, 17.30s/it]100%|██████████| 498/498 [2:23:49<00:00, 17.30s/it]                                                   {'train_runtime': 8630.0566, 'train_samples_per_second': 6.952, 'train_steps_per_second': 0.058, 'train_loss': 1.8643393727191482, 'num_tokens': 15336074.0, 'mean_token_accuracy': 0.7320761550217867, 'epoch': 2.98}
100%|██████████| 498/498 [2:23:50<00:00, 17.30s/it]100%|██████████| 498/498 [2:23:50<00:00, 17.33s/it]
Training finished.
Saving final adapter to: ./trained_adapters/en_clm_adapter
Adapter en_clm_adapter saved successfully.
--- Finished training and saved: en_clm_adapter ---

